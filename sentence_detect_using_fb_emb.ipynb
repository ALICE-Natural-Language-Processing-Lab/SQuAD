{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import torch\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !conda update pandas --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paras = list(train[\"context\"].drop_duplicates().reset_index(drop= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# blob = TextBlob(\" \".join(paras))\n",
    "# sentences = [item.raw for item in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# questions = list(train[\"question\"])\n",
    "# blob = TextBlob(\" \".join(questions))\n",
    "# questions = [item.raw for item in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in questions: sentences.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infersent = torch.load('InferSent/encoder/infersent.allnli.pickle', map_location=lambda storage, loc: storage)\n",
    "# infersent.set_glove_path(\"InferSent/dataset/GloVe/glove.840B.300d.txt\")\n",
    "# infersent.build_vocab(sentences, tokenize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Embedding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/dict_embeddings1.pickle\", \"rb\") as f:\n",
    "    d1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/dict_embeddings2.pickle\", \"rb\") as f:\n",
    "    d2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_emb = dict(d1)\n",
    "dict_emb.update(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179862"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del d1, d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target(x):\n",
    "    idx = -1\n",
    "    for i in range(len(x[\"sentences\"])):\n",
    "        if x[\"text\"] in x[\"sentences\"][i]: idx = i\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>515</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_start                                            context  \\\n",
       "0           515  Architecturally, the school has a Catholic cha...   \n",
       "1           188  Architecturally, the school has a Catholic cha...   \n",
       "2           279  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "\n",
       "                         text  \n",
       "0  Saint Bernadette Soubirous  \n",
       "1   a copper statue of Christ  \n",
       "2           the Main Building  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87598, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train):\n",
    "    \n",
    "    print(\"step 1\")\n",
    "    train['sentences'] = train['context'].apply(lambda x: [item.raw for item in TextBlob(x).sentences])\n",
    "    \n",
    "    print(\"step 2\")\n",
    "    train[\"target\"] = train.apply(get_target, axis = 1)\n",
    "    \n",
    "    print(\"step 3\")\n",
    "    train['sent_emb'] = train['sentences'].apply(lambda x: [dict_emb[item][0] if item in\\\n",
    "                                                           dict_emb else np.zeros(4096) for item in x])\n",
    "    print(\"step 4\")\n",
    "    train['quest_emb'] = train['question'].apply(lambda x: dict_emb[x] if x in dict_emb else np.zeros(4096) )\n",
    "        \n",
    "    return train   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n"
     ]
    }
   ],
   "source": [
    "train = process_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>quest_emb</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>515</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.11010079, 0.11422941, 0.11560896, 0.054894...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.10951651, 0.110306226, 0.052100066, 0.0305...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.011956469, 0.14930707, 0.026600493, 0.0527...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_start                                            context  \\\n",
       "0           515  Architecturally, the school has a Catholic cha...   \n",
       "1           188  Architecturally, the school has a Catholic cha...   \n",
       "2           279  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "\n",
       "                         text  \\\n",
       "0  Saint Bernadette Soubirous   \n",
       "1   a copper statue of Christ   \n",
       "2           the Main Building   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Architecturally, the school has a Catholic ch...   \n",
       "2  [Architecturally, the school has a Catholic ch...   \n",
       "\n",
       "                                           quest_emb  target  \\\n",
       "0  [[0.11010079, 0.11422941, 0.11560896, 0.054894...       5   \n",
       "1  [[0.10951651, 0.110306226, 0.052100066, 0.0305...       2   \n",
       "2  [[0.011956469, 0.14930707, 0.026600493, 0.0527...       3   \n",
       "\n",
       "                                            sent_emb  \n",
       "0  [[0.055199966, 0.05013141, 0.047870383, 0.0162...  \n",
       "1  [[0.055199966, 0.05013141, 0.047870383, 0.0162...  \n",
       "2  [[0.055199966, 0.05013141, 0.047870383, 0.0162...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Cosine & Euclidean Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_sim(x):\n",
    "    li = []\n",
    "    for item in x[\"sent_emb\"]:\n",
    "        li.append(spatial.distance.cosine(item,x[\"quest_emb\"][0]))\n",
    "    return li   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_idx(distances):\n",
    "    return np.argmin(distances)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(train):\n",
    "    \n",
    "    train[\"cosine_sim\"] = train.apply(cosine_sim, axis = 1)\n",
    "    train[\"diff\"] = (train[\"quest_emb\"] - train[\"sent_emb\"])**2\n",
    "    train[\"euclidean_dis\"] = train[\"diff\"].apply(lambda x: list(np.sum(x, axis = 1)))\n",
    "    del train[\"diff\"]\n",
    "    \n",
    "    train[\"pred_idx_cos\"] = train[\"cosine_sim\"].apply(lambda x: pred_idx(x))\n",
    "    train[\"pred_idx_euc\"] = train[\"euclidean_dis\"].apply(lambda x: pred_idx(x))\n",
    "    \n",
    "    return train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = predictions(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>quest_emb</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_emb</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>pred_idx_cos</th>\n",
       "      <th>pred_idx_euc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>515</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.11010079, 0.11422941, 0.11560896, 0.054894...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "      <td>[0.424736299052452, 0.36405004106069117, 0.347...</td>\n",
       "      <td>[14.563858, 15.262212, 17.398178, 14.272491, 1...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.10951651, 0.110306226, 0.052100066, 0.0305...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "      <td>[0.45407456884452513, 0.32262004808444933, 0.3...</td>\n",
       "      <td>[12.889506, 12.285219, 16.843704, 8.361172, 11...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[0.011956469, 0.14930707, 0.026600493, 0.0527...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.055199966, 0.05013141, 0.047870383, 0.0162...</td>\n",
       "      <td>[0.39585783692319865, 0.29170832145169434, 0.3...</td>\n",
       "      <td>[11.857297, 11.392319, 15.061656, 7.1847134, 8...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_start                                            context  \\\n",
       "0           515  Architecturally, the school has a Catholic cha...   \n",
       "1           188  Architecturally, the school has a Catholic cha...   \n",
       "2           279  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "\n",
       "                         text  \\\n",
       "0  Saint Bernadette Soubirous   \n",
       "1   a copper statue of Christ   \n",
       "2           the Main Building   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Architecturally, the school has a Catholic ch...   \n",
       "2  [Architecturally, the school has a Catholic ch...   \n",
       "\n",
       "                                           quest_emb  target  \\\n",
       "0  [[0.11010079, 0.11422941, 0.11560896, 0.054894...       5   \n",
       "1  [[0.10951651, 0.110306226, 0.052100066, 0.0305...       2   \n",
       "2  [[0.011956469, 0.14930707, 0.026600493, 0.0527...       3   \n",
       "\n",
       "                                            sent_emb  \\\n",
       "0  [[0.055199966, 0.05013141, 0.047870383, 0.0162...   \n",
       "1  [[0.055199966, 0.05013141, 0.047870383, 0.0162...   \n",
       "2  [[0.055199966, 0.05013141, 0.047870383, 0.0162...   \n",
       "\n",
       "                                          cosine_sim  \\\n",
       "0  [0.424736299052452, 0.36405004106069117, 0.347...   \n",
       "1  [0.45407456884452513, 0.32262004808444933, 0.3...   \n",
       "2  [0.39585783692319865, 0.29170832145169434, 0.3...   \n",
       "\n",
       "                                       euclidean_dis  pred_idx_cos  \\\n",
       "0  [14.563858, 15.262212, 17.398178, 14.272491, 1...             5   \n",
       "1  [12.889506, 12.285219, 16.843704, 8.361172, 11...             3   \n",
       "2  [11.857297, 11.392319, 15.061656, 7.1847134, 8...             3   \n",
       "\n",
       "   pred_idx_euc  \n",
       "0             5  \n",
       "1             3  \n",
       "2             3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.424736299052452,\n",
       " 0.36405004106069117,\n",
       " 0.3477550016687636,\n",
       " 0.3942415731988862,\n",
       " 0.37102476524939887,\n",
       " 0.1856902254140269,\n",
       " 0.35192069116776403]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[\"cosine_sim\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.563858, 15.262212, 17.398178, 14.272491, 13.339654, 9.336262, 15.720997]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[\"euclidean_dis\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(target, predicted):\n",
    "    \n",
    "    acc = (target==predicted).sum()/len(target)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for  euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44856046941711\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predicted[\"target\"], predicted[\"pred_idx_euc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6338843352587958\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predicted[\"target\"], predicted[\"pred_idx_cos\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted.to_csv(\"train_detect_sent.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"target\"] = train.apply(lambda x: get_index(x[\"text\"], x[\"sentence\"]))\n",
    "\n",
    "train[\"cosine_sim\"] = train.apply(lambda x: cosine_sim(x[\"quest_emb\"],x[\"sent_emb\"]))\n",
    "train[\"euclidean_dis\"] = train.apply(lambda x: euclidean_dis(x[\"quest_emb\"],x[\"sent_emb\"]))\n",
    "train[\"pred_idx_cos\"] = train.apply(lambda x: pred_idx(x[\"cosine_sim\"]))\n",
    "train[\"pred_idx_euc\"] = train.apply(lambda x: pred_idx(x[\"euclidean_dist\"]))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
